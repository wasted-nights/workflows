import requests
from bs4 import BeautifulSoup
import os
from datetime import datetime
import time
import urllib3

# ç¦ç”¨ä¸å®‰å…¨è«‹æ±‚è­¦å‘Š
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# è®€å– LINE Notify Token
token = os.getenv('LINE_NOTIFY_TOKEN')

# æ›´æ–° headers ä»¥æ¨¡æ“¬ç€è¦½å™¨ä¸¦ç¹éé©—è­‰
headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
    'Referer': 'https://www.ptt.cc/bbs/Drama-Ticket/index.html',
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',
    'Accept-Encoding': 'gzip, deflate, br',
    'Accept-Language': 'en-US,en;q=0.9',
    'Connection': 'keep-alive',
    'Cookie': 'over18=1'  # ç¹é 18 æ­²é™åˆ¶
}

# å»ºç«‹ä¸€å€‹ session ä¾†ä¿æŒæœƒè©±
session = requests.Session()
session.headers.update(headers)

# PTT çœ‹æ¿ URL
url = 'https://www.ptt.cc/bbs/Drama-Ticket/index.html'

# è¨­å®šé—œéµå­—
keywords = ['å€‰æœ¨', 'è§’é‡']

# è¨­å®šæ—¥æœŸç¯©é¸ï¼Œåƒ…è™•ç† 2025/02/06 ä¹‹å¾Œçš„æ–‡ç« 
start_date = datetime(2025, 2, 6)

# ä¿å­˜å·²è™•ç†éçš„æ¨™é¡Œ
processed_titles_file = 'processed_titles.txt'

# ç™¼é€ LINE é€šçŸ¥çš„å‡½å¼
def send_line_notify(message):
    payload = {'message': message}
    response = requests.post('https://notify-api.line.me/api/notify', headers=headers, data=payload)
    return response.status_code

# è®€å–å·²è™•ç†éçš„æ¨™é¡Œ
def read_processed_titles():
    if os.path.exists(processed_titles_file):
        with open(processed_titles_file, 'r', encoding='utf-8') as file:
            return set(file.read().splitlines())
    return set()

# æ›´æ–°å·²è™•ç†éçš„æ¨™é¡Œ
def save_processed_title(title):
    with open(processed_titles_file, 'a', encoding='utf-8') as file:
        file.write(title + '\n')

# æŠ“å– PTT çœ‹æ¿çš„æ–‡ç« æ¨™é¡Œ
def fetch_ptt_titles(max_retries=3):
    print("===== é–‹å§‹çˆ¬å– PTT =====")
    
    for attempt in range(max_retries):
        try:
            # ä½¿ç”¨ verify=False å¿½ç•¥ SSL é©—è­‰
            response = session.get(url, verify=False, timeout=10)
            
            print(f"HTTP ç‹€æ…‹ç¢¼: {response.status_code}")
            
            if response.status_code == 200:
                # æª¢æŸ¥æ˜¯å¦æœ‰é©—è­‰ç¢¼
                if 'é©—è­‰ç¢¼' in response.text:
                    print("âŒ é‡åˆ°é©—è­‰ç¢¼ï¼Œéœ€è¦æ‰‹å‹•è™•ç†")
                    return
                
                soup = BeautifulSoup(response.text, 'html.parser')
                articles = soup.find_all('div', class_='r-ent')
                
                print(f"ğŸ” æ‰¾åˆ° {len(articles)} ç¯‡æ–‡ç« ")
                
                found_match = False
                processed_titles = read_processed_titles()
                
                for article in articles:
                    title_div = article.find('div', class_='title')
                    date_div = article.find('div', class_='meta').find('div', class_='date')
                    
                    if title_div.a and date_div:
                        article_title = title_div.a.text.strip()
                        article_date = date_div.text.strip()
                        article_datetime = datetime.strptime(f"2025/{article_date}", "%Y/%m/%d")
                        
                        print(f"ğŸ“Œ æŠ“å–åˆ°çš„æ¨™é¡Œ: {article_title} ({article_date})")
                        
                        if article_datetime >= start_date:
                            if article_title not in processed_titles:
                                if any(keyword in article_title for keyword in keywords):
                                    print(f"âœ… é—œéµå­—åŒ¹é…æˆåŠŸ: {article_title}")
                                    send_line_notify(f"æ–°æ–‡ç« ï¼š{article_title}")
                                    save_processed_title(article_title)
                                    found_match = True
                            else:
                                print(f"ğŸ“Œ å·²è™•ç†éçš„æ¨™é¡Œ: {article_title}")
                
                if not found_match:
                    print("âŒ æ²’æœ‰ç¬¦åˆçš„é—œéµå­—ï¼Œé€™æ¬¡æ²’æœ‰ç™¼é€é€šçŸ¥")
                
                break  # æˆåŠŸå¾Œè·³å‡ºé‡è©¦è¿´åœˆ
            
            time.sleep(2)  # ç­‰å¾…é‡è©¦
        
        except Exception as e:
            print(f"âŒ ç¬¬ {attempt+1} æ¬¡å˜—è©¦å¤±æ•—: {e}")
    
    print("===== çˆ¬å– PTT çµæŸ =====")

# åŸ·è¡Œçˆ¬å–å‡½å¼
fetch_ptt_titles()
