import requests
from bs4 import BeautifulSoup
import os
from datetime import datetime

# è®€å– LINE Notify Token
token = os.getenv('LINE_NOTIFY_TOKEN')
headers = {'Authorization': f'Bearer {token}'}

# PTT çœ‹æ¿ URL
url = 'https://www.ptt.cc/bbs/Drama-Ticket/index.html'

# è¨­å®šé—œéµå­—
keywords = ['å€‰æœ¨', 'è§’é‡']  # é€™è£¡æ”¾ä¸Šä½ è¦æª¢æŸ¥çš„é—œéµå­—

# è¨­å®šæ—¥æœŸç¯©é¸ï¼Œåƒ…è™•ç† 2025/02/06 ä¹‹å¾Œçš„æ–‡ç« 
start_date = datetime(2025, 2, 6)

# ä¿å­˜å·²è™•ç†éçš„æ¨™é¡Œ
processed_titles_file = 'processed_titles.txt'

# ç™¼é€ LINE é€šçŸ¥çš„å‡½å¼
def send_line_notify(message):
    payload = {'message': message}
    response = requests.post('https://notify-api.line.me/api/notify', headers=headers, data=payload)
    return response.status_code

# è®€å–å·²è™•ç†éçš„æ¨™é¡Œ
def read_processed_titles():
    if os.path.exists(processed_titles_file):
        with open(processed_titles_file, 'r', encoding='utf-8') as file:
            return set(file.read().splitlines())  # è¿”å›å·²è™•ç†æ¨™é¡Œçš„é›†åˆ
    return set()

# æ›´æ–°å·²è™•ç†éçš„æ¨™é¡Œ
def save_processed_title(title):
    with open(processed_titles_file, 'a', encoding='utf-8') as file:
        file.write(title + '\n')  # ä¿å­˜è™•ç†éçš„æ¨™é¡Œ

# æŠ“å– PTT çœ‹æ¿çš„æ–‡ç« æ¨™é¡Œ
def fetch_ptt_titles():
    print("===== é–‹å§‹çˆ¬å– PTT =====")

    response = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})
    print(f"HTTP ç‹€æ…‹ç¢¼: {response.status_code}")

    if response.status_code != 200:
        print("âŒ çˆ¬å–å¤±æ•—ï¼Œè«‹æª¢æŸ¥ URL æˆ– PTT æ˜¯å¦æœ‰è®Šæ›´")
        return

    soup = BeautifulSoup(response.text, 'html.parser')
    articles = soup.find_all('div', class_='r-ent')  # æ‰¾åˆ°æ‰€æœ‰æ–‡ç« å€å¡Š

    print(f"ğŸ” æ‰¾åˆ° {len(articles)} ç¯‡æ–‡ç« ")

    found_match = False  # ç”¨ä¾†æ¨™è¨˜æ˜¯å¦æœ‰ç¬¦åˆé—œéµå­—çš„æ–‡ç« 
    processed_titles = read_processed_titles()  # è®€å–å·²è™•ç†çš„æ¨™é¡Œ

    for article in articles:
        title_div = article.find('div', class_='title')
        date_div = article.find('div', class_='meta').find('div', class_='date')

        if title_div.a and date_div:
            article_title = title_div.a.text.strip()
            article_date = date_div.text.strip()  # å–å¾—æ—¥æœŸï¼ˆæ ¼å¼: 2/06ï¼‰

            # è½‰æ›æ—¥æœŸæ ¼å¼ï¼Œè®“å®ƒè®Šæˆ datetime æ ¼å¼ä¾†æ¯”è¼ƒ
            article_datetime = datetime.strptime(f"2025/{article_date}", "%Y/%m/%d")

            print(f"ğŸ“Œ æŠ“å–åˆ°çš„æ¨™é¡Œ: {article_title} ({article_date})")

            # åªè™•ç† 2025/02/06 ä¹‹å¾Œçš„æ–‡ç« 
            if article_datetime >= start_date:
                # æª¢æŸ¥æ¨™é¡Œæ˜¯å¦å·²ç¶“è™•ç†é
                if article_title not in processed_titles:
                    if any(keyword in article_title for keyword in keywords):
                        print(f"âœ… é—œéµå­—åŒ¹é…æˆåŠŸ: {article_title}")
                        send_line_notify(f"æ–°æ–‡ç« ï¼š{article_title}")
                        save_processed_title(article_title)  # ä¿å­˜å·²è™•ç†éçš„æ¨™é¡Œ
                        found_match = True
                else:
                    print(f"ğŸ“Œ å·²è™•ç†éçš„æ¨™é¡Œ: {article_title}")

    if not found_match:
        print("âŒ æ²’æœ‰ç¬¦åˆçš„é—œéµå­—ï¼Œé€™æ¬¡æ²’æœ‰ç™¼é€é€šçŸ¥")

    print("===== çˆ¬å– PTT çµæŸ =====")

# åŸ·è¡Œçˆ¬å–å‡½å¼
fetch_ptt_titles()
